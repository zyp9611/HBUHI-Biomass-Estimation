{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eba7bb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Total samples: 75\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import libraries + path + data reading & merging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from joblib import Parallel, delayed\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from scipy.stats import gaussian_kde, probplot, shapiro\n",
    "import statsmodels.api as sm\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# ==============================================================\n",
    "# 1. Paths & site info\n",
    "# ==============================================================\n",
    "site_info = [\n",
    "    (r\"E:\\jupyter_data\\Hapke\\Submit\\data\\Original\\ave_01_o.csv\",\n",
    "     r\"E:\\jupyter_data\\Hapke\\Submit\\data\\Original\\shice_01.csv\",\n",
    "     r\"E:\\jupyter_data\\Hapke\\Submit\\data\\processed\\Hapke_result\",\n",
    "     30.57, 0.0, 153.28, 59.31, 0.0, 261.17, \"01\"),\n",
    "    (r\"E:\\jupyter_data\\Hapke\\Submit\\data\\Original\\ave_03_o.csv\",\n",
    "     r\"E:\\jupyter_data\\Hapke\\Submit\\data\\Original\\shice_03.csv\",\n",
    "     r\"E:\\jupyter_data\\Hapke\\Submit\\data\\processed\\Hapke_result\",\n",
    "     37.42, 0.0, 130.25, 43.69, 0.0, 241.63, \"03\")\n",
    "]\n",
    "\n",
    "output_root = site_info[0][2]\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# ==============================================================\n",
    "# 2. Plot settings\n",
    "# ==============================================================\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ==============================================================\n",
    "# 3. Hapke model functions\n",
    "# ==============================================================\n",
    "def cos_g(i, e, phi): return np.cos(i) * np.cos(e) + np.sin(i) * np.sin(e) * np.cos(phi)\n",
    "def mu_0(i): return np.cos(i)\n",
    "def mu(e): return np.cos(e)\n",
    "\n",
    "def B_g(g, B_0, h):\n",
    "    tan_half_g = np.tan(g / 2)\n",
    "    return B_0 / (1 + (1 / h) * tan_half_g if tan_half_g != 0 else 1 + 1e-10)\n",
    "\n",
    "def P_g(g, b, c):\n",
    "    cos_g_val = np.cos(g)\n",
    "    d1 = max(1 - 2 * b * cos_g_val + b**2, 1e-10)\n",
    "    d2 = max(1 + 2 * b * cos_g_val + b**2, 1e-10)\n",
    "    b = min(b, 0.99999)\n",
    "    term1 = ((1 + c) / 2) * (1 - b**2) / (d1)**1.5\n",
    "    term2 = ((1 - c) / 2) * (1 - b**2) / (d2)**1.5\n",
    "    return term1 + term2\n",
    "\n",
    "def H(mu, w): return (1 + 2 * mu) / (1 + 2 * mu * np.sqrt(1 - w))\n",
    "\n",
    "def R_hapke(mu_0, mu, g, w, B_0, h, b, c):\n",
    "    B = B_g(g, B_0, h)\n",
    "    P = P_g(g, b, c)\n",
    "    H0 = H(mu_0, w)\n",
    "    H_mu = H(mu, w)\n",
    "    return (w / (4 * np.pi * (mu_0 + mu))) * ((1 + B) * P + H0 * H_mu - 1)\n",
    "\n",
    "# ==============================================================\n",
    "# 4. Wavelength band definitions\n",
    "# ==============================================================\n",
    "wavelengths = [350 + (i-1)*4 for i in range(1, 165)]\n",
    "selected_wavelengths = wavelengths[10:154]\n",
    "band_range = (11, 154)\n",
    "n_bands = band_range[1] - band_range[0] + 1\n",
    "\n",
    "# ==============================================================\n",
    "# 5. Read & merge data\n",
    "# ==============================================================\n",
    "all_ref_1a, all_ref_1b, all_tree_ids, all_geom = [], [], [], []\n",
    "\n",
    "for idx, (inp_file, shice_file, _, i1_deg, e1_deg, phi1_deg,\n",
    "          i2_deg, e2_deg, phi2_deg, prefix) in enumerate(site_info):\n",
    "    shice_df = pd.read_csv(shice_file)\n",
    "    valid_ids = shice_df['Tree_ID'].values\n",
    "    df = pd.read_csv(inp_file)\n",
    "    df = df[df['Tree_ID'].isin(valid_ids)].copy()\n",
    "    df['Tree_ID'] = prefix + '_' + df['Tree_ID'].astype(str)\n",
    "\n",
    "    start_band, end_band = band_range\n",
    "    bands_1a = [f'1a_{350 + (i-1)*4}nm' for i in range(start_band, end_band + 1)]\n",
    "    bands_1b = [f'1b_{350 + (i-1)*4}nm' for i in range(start_band, end_band + 1)]\n",
    "\n",
    "    ref_1a = df[bands_1a].values\n",
    "    ref_1b = df[bands_1b].values\n",
    "    tree_ids = df['Tree_ID'].values\n",
    "\n",
    "    all_ref_1a.append(ref_1a)\n",
    "    all_ref_1b.append(ref_1b)\n",
    "    all_tree_ids.extend(tree_ids)\n",
    "\n",
    "    i1, e1, phi1 = map(math.radians, [i1_deg, e1_deg, phi1_deg])\n",
    "    i2, e2, phi2 = map(math.radians, [i2_deg, e2_deg, phi2_deg])\n",
    "    mu0_1 = mu_0(i1); mu_1 = mu(e1); g1 = np.arccos(cos_g(i1, e1, phi1))\n",
    "    mu0_2 = mu_0(i2); mu_2 = mu(e2); g2 = np.arccos(cos_g(i2, e2, phi2))\n",
    "    geom = (mu0_1, mu_1, g1, mu0_2, mu_2, g2)\n",
    "    all_geom.extend([geom] * len(tree_ids))\n",
    "\n",
    "actual_reflectance_1a = np.vstack(all_ref_1a)\n",
    "actual_reflectance_1b = np.vstack(all_ref_1b)\n",
    "tree_ids = np.array(all_tree_ids)\n",
    "n_samples = actual_reflectance_1a.shape[0]\n",
    "\n",
    "# Reindex tree_ids\n",
    "new_tree_id = np.arange(1, n_samples + 1)\n",
    "tree_id_map = pd.DataFrame({'Original_Tree_ID': tree_ids, 'New_Tree_ID': new_tree_id})\n",
    "\n",
    "print(f\"Data loaded. Total samples: {n_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2ef58ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parallel fitting (75 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  75 | elapsed:    4.6s remaining:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  75 | elapsed:    5.8s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  75 | elapsed:    6.4s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  75 | elapsed:    7.6s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  75 | elapsed:    8.1s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of  75 | elapsed:    8.4s remaining:    0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting completed, parameters have been saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:   13.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Optimization fitting + save parameters & fitted values\n",
    "def optimize_sample_with_geom(sample_idx, actual_1a, actual_1b, geom_param):\n",
    "    mu0_1, mu_1, g1, mu0_2, mu_2, g2 = geom_param\n",
    "    def objective(params):\n",
    "        w_vals = np.clip(params[:n_bands], 0, 1)\n",
    "        B0 = np.clip(params[n_bands], 0, 1)\n",
    "        h = np.clip(params[n_bands+1], 0.01, 1)\n",
    "        b = np.clip(params[n_bands+2], 0, 1)\n",
    "        c = np.clip(params[n_bands+3], -1, 1)\n",
    "        model_1a = R_hapke(mu0_1, mu_1, g1, w_vals, B0, h, b, c)\n",
    "        model_1b = R_hapke(mu0_2, mu_2, g2, w_vals, B0, h, b, c)\n",
    "        return np.sum((model_1a - actual_1a)**2) + np.sum((model_1b - actual_1b)**2)\n",
    "    init = np.concatenate([np.full(n_bands, 0.5), [1.0, 0.1, 0.5, 0.0]])\n",
    "    bounds = [(0,1)]*n_bands + [(0,1), (0.01,1), (0,1), (-1,1)]\n",
    "    res = minimize(objective, init, bounds=bounds, method='L-BFGS-B', options={'maxfun': 1_000_000, 'maxiter': 1_000_000})\n",
    "    if not res.success:\n",
    "        print(f\"Warning: Sample {sample_idx} optimization failed: {res.message}\")\n",
    "    w = res.x[:n_bands]\n",
    "    B0, h, b, c = res.x[n_bands:n_bands+4]\n",
    "    fit_1a = R_hapke(mu0_1, mu_1, g1, w, B0, h, b, c)\n",
    "    fit_1b = R_hapke(mu0_2, mu_2, g2, w, B0, h, b, c)\n",
    "    return w, B0, h, b, c, fit_1a, fit_1b\n",
    "\n",
    "print(f\"Starting parallel fitting ({n_samples} samples)...\")\n",
    "results = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(optimize_sample_with_geom)(i, actual_reflectance_1a[i], actual_reflectance_1b[i], all_geom[i])\n",
    "    for i in range(n_samples)\n",
    ")\n",
    "w_est, B0_est, h_est, b_est, c_est, fit_1a_list, fit_1b_list = zip(*results)\n",
    "w_est = list(w_est); B0_est = list(B0_est); h_est = list(h_est)\n",
    "b_est = list(b_est); c_est = list(c_est)\n",
    "fit_1a_list = list(fit_1a_list); fit_1b_list = list(fit_1b_list)\n",
    "\n",
    "# Save parameters\n",
    "w_all = np.column_stack(w_est).T\n",
    "w_cols = {f'w_{wl}nm': w_all[:, i] for i, wl in enumerate(selected_wavelengths)}\n",
    "params_df = pd.DataFrame({'New_Tree_ID': new_tree_id, 'Original_Tree_ID': tree_ids,\n",
    "                          'B_0': B0_est, 'h': h_est, 'b': b_est, 'c': c_est})\n",
    "params_df = pd.concat([params_df, pd.DataFrame(w_cols)], axis=1)\n",
    "params_df.to_csv(os.path.join(output_root, \"hapke_parameters_merged.csv\"), index=False)\n",
    "\n",
    "# Save fitted reflectance\n",
    "fitted_cols = [pd.Series(new_tree_id, name='New_Tree_ID'), pd.Series(tree_ids, name='Original_Tree_ID')]\n",
    "for i, wl in enumerate(selected_wavelengths):\n",
    "    col_1a = [fit_1a_list[j][i] for j in range(n_samples)]\n",
    "    col_1b = [fit_1b_list[j][i] for j in range(n_samples)]\n",
    "    fitted_cols.append(pd.Series(col_1a, name=f'Fitted_1a_{wl}nm'))\n",
    "    fitted_cols.append(pd.Series(col_1b, name=f'Fitted_1b_{wl}nm'))\n",
    "pd.concat(fitted_cols, axis=1).to_csv(os.path.join(output_root, \"merged_fitted_reflectance_390-962.csv\"), index=False)\n",
    "\n",
    "print(\"Fitting completed, parameters have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2bab1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
