{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries + path + data reading & merging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from joblib import Parallel, delayed\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from scipy.stats import gaussian_kde, probplot, shapiro\n",
    "import statsmodels.api as sm\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# ==============================================================\n",
    "# 1. Paths & site info\n",
    "# ==============================================================\n",
    "site_info = [\n",
    "    (r\"E:\\jupyter_data\\Hapke\\Submit\\data\\Original\\ave_01_o.csv\",\n",
    "     r\"E:\\jupyter_data\\Hapke\\Submit\\data\\Original\\shice_01.csv\",\n",
    "     r\"E:\\jupyter_data\\Hapke\\Submit\\data\\processed\\Hapke_result\",\n",
    "     30.57, 0.0, 153.28, 59.31, 0.0, 261.17, \"01\"),\n",
    "    (r\"E:\\jupyter_data\\Hapke\\Submit\\data\\Original\\ave_03_o.csv\",\n",
    "     r\"E:\\jupyter_data\\Hapke\\Submit\\data\\Original\\shice_03.csv\",\n",
    "     r\"E:\\jupyter_data\\Hapke\\Submit\\data\\processed\\Hapke_result\",\n",
    "     37.42, 0.0, 130.25, 43.69, 0.0, 241.63, \"03\")\n",
    "]\n",
    "\n",
    "output_root = site_info[0][2]\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# ==============================================================\n",
    "# 2. Plot settings\n",
    "# ==============================================================\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ==============================================================\n",
    "# 3. Hapke model functions\n",
    "# ==============================================================\n",
    "def cos_g(i, e, phi): return np.cos(i) * np.cos(e) + np.sin(i) * np.sin(e) * np.cos(phi)\n",
    "def mu_0(i): return np.cos(i)\n",
    "def mu(e): return np.cos(e)\n",
    "\n",
    "def B_g(g, B_0, h):\n",
    "    tan_half_g = np.tan(g / 2)\n",
    "    return B_0 / (1 + (1 / h) * tan_half_g if tan_half_g != 0 else 1 + 1e-10)\n",
    "\n",
    "def P_g(g, b, c):\n",
    "    cos_g_val = np.cos(g)\n",
    "    d1 = max(1 - 2 * b * cos_g_val + b**2, 1e-10)\n",
    "    d2 = max(1 + 2 * b * cos_g_val + b**2, 1e-10)\n",
    "    b = min(b, 0.99999)\n",
    "    term1 = ((1 + c) / 2) * (1 - b**2) / (d1)**1.5\n",
    "    term2 = ((1 - c) / 2) * (1 - b**2) / (d2)**1.5\n",
    "    return term1 + term2\n",
    "\n",
    "def H(mu, w): return (1 + 2 * mu) / (1 + 2 * mu * np.sqrt(1 - w))\n",
    "\n",
    "def R_hapke(mu_0, mu, g, w, B_0, h, b, c):\n",
    "    B = B_g(g, B_0, h)\n",
    "    P = P_g(g, b, c)\n",
    "    H0 = H(mu_0, w)\n",
    "    H_mu = H(mu, w)\n",
    "    return (w / (4 * np.pi * (mu_0 + mu))) * ((1 + B) * P + H0 * H_mu - 1)\n",
    "\n",
    "# ==============================================================\n",
    "# 4. Wavelength band definitions\n",
    "# ==============================================================\n",
    "wavelengths = [350 + (i-1)*4 for i in range(1, 165)]\n",
    "selected_wavelengths = wavelengths[10:154]\n",
    "band_range = (11, 154)\n",
    "n_bands = band_range[1] - band_range[0] + 1\n",
    "\n",
    "# ==============================================================\n",
    "# 5. Read & merge data\n",
    "# ==============================================================\n",
    "all_ref_1a, all_ref_1b, all_tree_ids, all_geom = [], [], [], []\n",
    "\n",
    "for idx, (inp_file, shice_file, _, i1_deg, e1_deg, phi1_deg,\n",
    "          i2_deg, e2_deg, phi2_deg, prefix) in enumerate(site_info):\n",
    "    shice_df = pd.read_csv(shice_file)\n",
    "    valid_ids = shice_df['Tree_ID'].values\n",
    "    df = pd.read_csv(inp_file)\n",
    "    df = df[df['Tree_ID'].isin(valid_ids)].copy()\n",
    "    df['Tree_ID'] = prefix + '_' + df['Tree_ID'].astype(str)\n",
    "\n",
    "    start_band, end_band = band_range\n",
    "    bands_1a = [f'1a_{350 + (i-1)*4}nm' for i in range(start_band, end_band + 1)]\n",
    "    bands_1b = [f'1b_{350 + (i-1)*4}nm' for i in range(start_band, end_band + 1)]\n",
    "\n",
    "    ref_1a = df[bands_1a].values\n",
    "    ref_1b = df[bands_1b].values\n",
    "    tree_ids = df['Tree_ID'].values\n",
    "\n",
    "    all_ref_1a.append(ref_1a)\n",
    "    all_ref_1b.append(ref_1b)\n",
    "    all_tree_ids.extend(tree_ids)\n",
    "\n",
    "    i1, e1, phi1 = map(math.radians, [i1_deg, e1_deg, phi1_deg])\n",
    "    i2, e2, phi2 = map(math.radians, [i2_deg, e2_deg, phi2_deg])\n",
    "    mu0_1 = mu_0(i1); mu_1 = mu(e1); g1 = np.arccos(cos_g(i1, e1, phi1))\n",
    "    mu0_2 = mu_0(i2); mu_2 = mu(e2); g2 = np.arccos(cos_g(i2, e2, phi2))\n",
    "    geom = (mu0_1, mu_1, g1, mu0_2, mu_2, g2)\n",
    "    all_geom.extend([geom] * len(tree_ids))\n",
    "\n",
    "actual_reflectance_1a = np.vstack(all_ref_1a)\n",
    "actual_reflectance_1b = np.vstack(all_ref_1b)\n",
    "tree_ids = np.array(all_tree_ids)\n",
    "n_samples = actual_reflectance_1a.shape[0]\n",
    "\n",
    "# Reindex tree_ids\n",
    "new_tree_id = np.arange(1, n_samples + 1)\n",
    "tree_id_map = pd.DataFrame({'Original_Tree_ID': tree_ids, 'New_Tree_ID': new_tree_id})\n",
    "tree_id_map.to_csv(os.path.join(output_root, \"Tree_ID_mapping.csv\"), index=False)\n",
    "\n",
    "print(f\"Data loaded. Total samples: {n_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef58ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Optimization fitting + save parameters & fitted values\n",
    "def optimize_sample_with_geom(sample_idx, actual_1a, actual_1b, geom_param):\n",
    "    mu0_1, mu_1, g1, mu0_2, mu_2, g2 = geom_param\n",
    "    def objective(params):\n",
    "        w_vals = np.clip(params[:n_bands], 0, 1)\n",
    "        B0 = np.clip(params[n_bands], 0, 1)\n",
    "        h = np.clip(params[n_bands+1], 0.01, 1)\n",
    "        b = np.clip(params[n_bands+2], 0, 1)\n",
    "        c = np.clip(params[n_bands+3], -1, 1)\n",
    "        model_1a = R_hapke(mu0_1, mu_1, g1, w_vals, B0, h, b, c)\n",
    "        model_1b = R_hapke(mu0_2, mu_2, g2, w_vals, B0, h, b, c)\n",
    "        return np.sum((model_1a - actual_1a)**2) + np.sum((model_1b - actual_1b)**2)\n",
    "    init = np.concatenate([np.full(n_bands, 0.5), [1.0, 0.1, 0.5, 0.0]])\n",
    "    bounds = [(0,1)]*n_bands + [(0,1), (0.01,1), (0,1), (-1,1)]\n",
    "    res = minimize(objective, init, bounds=bounds, method='L-BFGS-B', options={'maxfun': 1_000_000, 'maxiter': 1_000_000})\n",
    "    if not res.success:\n",
    "        print(f\"Warning: Sample {sample_idx} optimization failed: {res.message}\")\n",
    "    w = res.x[:n_bands]\n",
    "    B0, h, b, c = res.x[n_bands:n_bands+4]\n",
    "    fit_1a = R_hapke(mu0_1, mu_1, g1, w, B0, h, b, c)\n",
    "    fit_1b = R_hapke(mu0_2, mu_2, g2, w, B0, h, b, c)\n",
    "    return w, B0, h, b, c, fit_1a, fit_1b\n",
    "\n",
    "print(f\"Starting parallel fitting ({n_samples} samples)...\")\n",
    "results = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(optimize_sample_with_geom)(i, actual_reflectance_1a[i], actual_reflectance_1b[i], all_geom[i])\n",
    "    for i in range(n_samples)\n",
    ")\n",
    "w_est, B0_est, h_est, b_est, c_est, fit_1a_list, fit_1b_list = zip(*results)\n",
    "w_est = list(w_est); B0_est = list(B0_est); h_est = list(h_est)\n",
    "b_est = list(b_est); c_est = list(c_est)\n",
    "fit_1a_list = list(fit_1a_list); fit_1b_list = list(fit_1b_list)\n",
    "\n",
    "# Save parameters\n",
    "w_all = np.column_stack(w_est).T\n",
    "w_cols = {f'w_{wl}nm': w_all[:, i] for i, wl in enumerate(selected_wavelengths)}\n",
    "params_df = pd.DataFrame({'New_Tree_ID': new_tree_id, 'Original_Tree_ID': tree_ids,\n",
    "                          'B_0': B0_est, 'h': h_est, 'b': b_est, 'c': c_est})\n",
    "params_df = pd.concat([params_df, pd.DataFrame(w_cols)], axis=1)\n",
    "params_df.to_csv(os.path.join(output_root, \"hapke_parameters_merged.csv\"), index=False)\n",
    "\n",
    "# Save fitted reflectance\n",
    "fitted_cols = [pd.Series(new_tree_id, name='New_Tree_ID'), pd.Series(tree_ids, name='Original_Tree_ID')]\n",
    "for i, wl in enumerate(selected_wavelengths):\n",
    "    col_1a = [fit_1a_list[j][i] for j in range(n_samples)]\n",
    "    col_1b = [fit_1b_list[j][i] for j in range(n_samples)]\n",
    "    fitted_cols.append(pd.Series(col_1a, name=f'Fitted_1a_{wl}nm'))\n",
    "    fitted_cols.append(pd.Series(col_1b, name=f'Fitted_1b_{wl}nm'))\n",
    "pd.concat(fitted_cols, axis=1).to_csv(os.path.join(output_root, \"merged_fitted_reflectance_390-962.csv\"), index=False)\n",
    "\n",
    "print(\"Fitting completed, parameters have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be768826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Diagnostic Plots (can be run independently)\n",
    "n_samples_to_plot = n_samples          \n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Accuracy Metrics (unchanged)\n",
    "# --------------------------------------------------------------\n",
    "def calc_metrics(fit, act):\n",
    "    ss_tot = np.sum((act - act.mean())**2)\n",
    "    ss_res = np.sum((act - fit)**2)\n",
    "    r2 = 1 - ss_res/ss_tot if ss_tot else 0\n",
    "    rmse = np.sqrt(ss_res/len(act))\n",
    "    return r2, rmse\n",
    "\n",
    "all_act = np.concatenate([np.concatenate(actual_reflectance_1a),\n",
    "                          np.concatenate(actual_reflectance_1b)])\n",
    "all_fit = np.concatenate([np.concatenate(fit_1a_list),\n",
    "                          np.concatenate(fit_1b_list)])\n",
    "total_r2, total_rmse = calc_metrics(all_fit, all_act)\n",
    "\n",
    "sample_metrics = [\n",
    "    (new_tree_id[i], tree_ids[i],\n",
    "     *calc_metrics(np.concatenate([fit_1a_list[i], fit_1b_list[i]]),\n",
    "                   np.concatenate([actual_reflectance_1a[i], actual_reflectance_1b[i]])))\n",
    "    for i in range(n_samples)\n",
    "]\n",
    "\n",
    "# NEW: Statistics of R2 distribution for each sample\n",
    "r2_values = [metric[2] for metric in sample_metrics]  # Extract R2 for all samples\n",
    "r2_array = np.array(r2_values)\n",
    "\n",
    "# Calculate statistics\n",
    "r2_mean = np.mean(r2_array)\n",
    "r2_median = np.median(r2_array)\n",
    "r2_std = np.std(r2_array)\n",
    "r2_min = np.min(r2_array)\n",
    "r2_max = np.max(r2_array)\n",
    "r2_q1 = np.percentile(r2_array, 25)\n",
    "r2_q3 = np.percentile(r2_array, 75)\n",
    "r2_iqr = r2_q3 - r2_q1\n",
    "\n",
    "# Print statistics\n",
    "print(\"R2 distribution statistics for each sample:\")\n",
    "print(f\"Mean: {r2_mean:.4f}\")\n",
    "print(f\"Median: {r2_median:.4f}\")\n",
    "print(f\"Std Dev: {r2_std:.4f}\")\n",
    "print(f\"Min: {r2_min:.4f}\")\n",
    "print(f\"Max: {r2_max:.4f}\")\n",
    "print(f\"Q1 (25% percentile): {r2_q1:.4f}\")\n",
    "print(f\"Q3 (75% percentile): {r2_q3:.4f}\")\n",
    "print(f\"IQR (Q3 - Q1): {r2_iqr:.4f}\")\n",
    "\n",
    "# Optional: Save statistics to file (if needed)\n",
    "stats_file = os.path.join(output_root, 'r2_distribution_stats.txt')\n",
    "with open(stats_file, 'w') as f:\n",
    "    f.write(\"R2 distribution statistics for each sample:\\n\")\n",
    "    f.write(f\"Mean: {r2_mean:.4f}\\n\")\n",
    "    f.write(f\"Median: {r2_median:.4f}\\n\")\n",
    "    f.write(f\"Std Dev: {r2_std:.4f}\\n\")\n",
    "    f.write(f\"Min: {r2_min:.4f}\\n\")\n",
    "    f.write(f\"Max: {r2_max:.4f}\\n\")\n",
    "    f.write(f\"Q1 (25% percentile): {r2_q1:.4f}\\n\")\n",
    "    f.write(f\"Q3 (75% percentile): {r2_q3:.4f}\\n\")\n",
    "    f.write(f\"IQR (Q3 - Q1): {r2_iqr:.4f}\\n\")\n",
    "print(f\"R2 statistics have been saved to {stats_file}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Plotting (uniform style, no grid, no title)\n",
    "# --------------------------------------------------------------\n",
    "all_fitted_vals, all_residuals = [], []\n",
    "\n",
    "# ---------- 1. Overall scatter plot (density colored) ----------\n",
    "plt.figure(figsize=(5, 4))\n",
    "xy = np.vstack([all_act, all_fit])\n",
    "density = gaussian_kde(xy)(xy)\n",
    "density = (density - density.min()) / (density.max() - density.min())\n",
    "plt.scatter(all_act, all_fit, c=density, cmap='viridis_r', s=1, alpha=1)\n",
    "plt.colorbar(label='Point Density')\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='1:1 Line')\n",
    "plt.xlabel('Actual Reflectance')\n",
    "plt.ylabel('Fitted Reflectance')\n",
    "plt.legend(loc='lower right')\n",
    "plt.text(0.05, 0.93,\n",
    "         f'$R^2$ = {total_r2:.4f}\\nRMSE = {total_rmse:.4f}',\n",
    "         transform=plt.gca().transAxes, fontsize=10,\n",
    "         verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "plt.xlim(0, max(all_act.max(), all_fit.max()) * 1.1)\n",
    "plt.ylim(0, max(all_act.max(), all_fit.max()) * 1.1)\n",
    "plt.grid(False)   # Grid off\n",
    "plt.savefig(os.path.join(output_root,\n",
    "                         'scatter_actual_vs_fitted_merged_samples.png'),\n",
    "            dpi=600, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# ---------- 2. Loop over individual samples ----------\n",
    "for i in range(min(n_samples, n_samples_to_plot)):\n",
    "    new_id = new_tree_id[i]\n",
    "    sample_act = np.concatenate([actual_reflectance_1a[i],\n",
    "                                 actual_reflectance_1b[i]])\n",
    "    sample_fit = np.concatenate([fit_1a_list[i],\n",
    "                                 fit_1b_list[i]])\n",
    "    residuals = sample_act - sample_fit\n",
    "    all_fitted_vals.extend(sample_fit)\n",
    "    all_residuals.extend(residuals)\n",
    "\n",
    "    # ---- Individual scatter plot ----\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.scatter(sample_act, sample_fit, c='blue', s=1)\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='1:1 Line')\n",
    "    plt.xlabel('Actual Reflectance')\n",
    "    plt.ylabel('Fitted Reflectance')\n",
    "    plt.legend(loc='lower right')\n",
    "    r2, rmse = sample_metrics[i][2], sample_metrics[i][3]\n",
    "    plt.text(0.05, 0.93,\n",
    "             f'$R^2$ = {r2:.4f}\\nRMSE = {rmse:.4f}',\n",
    "             transform=plt.gca().transAxes, fontsize=10,\n",
    "             verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    plt.xlim(0, max(sample_act.max(), sample_fit.max()) * 1.1)\n",
    "    plt.ylim(0, max(sample_act.max(), sample_fit.max()) * 1.1)\n",
    "    plt.grid(False)\n",
    "    plt.savefig(os.path.join(output_root,\n",
    "                             f'scatter_Tree_ID_{new_id}_merged.png'),\n",
    "                dpi=600, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # ---- Residuals vs. Fitted (individual) ----\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.scatter(sample_fit, residuals, c='blue', s=15,\n",
    "                alpha=0.8, edgecolors='none')\n",
    "    if len(sample_fit) > 5:\n",
    "        smooth = sm.nonparametric.lowess(residuals, sample_fit, frac=0.3)\n",
    "        plt.plot(smooth[:, 0], smooth[:, 1], 'r-', lw=1.5,\n",
    "                 label='LOESS Trend')\n",
    "    plt.axhline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "    plt.xlabel('Fitted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.text(0.05, 0.93,\n",
    "             f'$R^2$ = {r2:.4f}\\nRMSE = {rmse:.4f}',\n",
    "             transform=plt.gca().transAxes, fontsize=10,\n",
    "             verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    plt.grid(False)\n",
    "    plt.savefig(os.path.join(output_root,\n",
    "                             f'residual_vs_fitted_Tree_ID_{new_id}.png'),\n",
    "                dpi=600, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # ---- QQ plot (individual) ----\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    probplot(residuals, dist=\"norm\", plot=plt)\n",
    "    lines = plt.gca().get_lines()\n",
    "    lines[0].set_color('blue')   # Points\n",
    "    lines[0].set_markersize(2)\n",
    "    lines[1].set_color('red')    # Reference line\n",
    "    plt.xlabel('Theoretical Quantiles')\n",
    "    plt.ylabel('Sample Quantiles')\n",
    "    plt.gca().set_title('')      # Ensure no title\n",
    "    plt.grid(False)\n",
    "    plt.savefig(os.path.join(output_root,\n",
    "                             f'qq_plot_New_Tree_ID_{new_id}.png'),\n",
    "                dpi=600, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # ---- Residual histogram (individual) ----\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.hist(residuals, bins=20, color='blue',\n",
    "             alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "    plt.xlabel('Residuals')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(False)\n",
    "    plt.savefig(os.path.join(output_root,\n",
    "                             f'residual_histogram_New_Tree_ID_{new_id}.png'),\n",
    "                dpi=600, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ---------- 3. Overall Residuals vs. Fitted (density) ----------\n",
    "all_fitted_vals = np.array(all_fitted_vals)\n",
    "all_residuals   = np.array(all_residuals)\n",
    "xy = np.vstack([all_fitted_vals, all_residuals])\n",
    "density = gaussian_kde(xy)(xy)\n",
    "density = (density - density.min()) / (density.max() - density.min() + 1e-8)\n",
    "\n",
    "plt.figure(figsize=(6, 4.5))\n",
    "scatter = plt.scatter(all_fitted_vals, all_residuals,\n",
    "                      c=density, cmap='viridis_r', s=2, alpha=0.7)\n",
    "plt.colorbar(scatter, label='Point Density')\n",
    "if len(all_fitted_vals) > 10:\n",
    "    smooth = sm.nonparametric.lowess(all_residuals, all_fitted_vals, frac=0.2)\n",
    "    plt.plot(smooth[:, 0], smooth[:, 1], 'r-', lw=2,\n",
    "             label='LOESS Trend')\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend(loc='lower right')\n",
    "plt.text(0.05, 0.93,\n",
    "         f'$R^2$ = {total_r2:.4f}\\nRMSE = {total_rmse:.4f}',\n",
    "         transform=plt.gca().transAxes, fontsize=10,\n",
    "         verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "plt.grid(False)\n",
    "plt.savefig(os.path.join(output_root,\n",
    "                         'overall_residual_vs_fitted_density.png'),\n",
    "            dpi=600, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# ---------- 4. Overall QQ plot ----------\n",
    "plt.figure(figsize=(5, 4))\n",
    "probplot(all_residuals, dist=\"norm\", plot=plt)\n",
    "lines = plt.gca().get_lines()\n",
    "lines[0].set_color('green')   # Points\n",
    "lines[1].set_color('red')     # Reference line\n",
    "lines[0].set_markersize(2)\n",
    "plt.xlabel('Theoretical Quantiles')\n",
    "plt.ylabel('Sample Quantiles')\n",
    "plt.gca().set_title('')\n",
    "plt.grid(False)\n",
    "plt.savefig(os.path.join(output_root, 'overall_qq_plot.png'),\n",
    "            dpi=600, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# ---------- 5. Overall residual histogram ----------\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.hist(all_residuals, bins=50, color='green',\n",
    "         alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(False)\n",
    "plt.savefig(os.path.join(output_root, 'overall_residual_histogram.png'),\n",
    "            dpi=600, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"Diagnostic plots saved (first {n_samples_to_plot} samples + overall plots)\")\n",
    "print(\"Diagnostic plotting complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48890f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Cell 4: Bootstrap & Overall Uncertainty (No Title)\n",
    "# ==============================================================\n",
    "n_bootstraps = 1000\n",
    "\n",
    "def bootstrap_sample(sample_idx, actual_1a, actual_1b, fitted_1a, fitted_1b, geom_param, new_id):\n",
    "    residuals_1a = actual_1a - fitted_1a\n",
    "    residuals_1b = actual_1b - fitted_1b\n",
    "    \n",
    "    boot_w = np.zeros((n_bootstraps, n_bands))\n",
    "    boot_B0 = np.zeros(n_bootstraps)\n",
    "    boot_h = np.zeros(n_bootstraps)\n",
    "    boot_b = np.zeros(n_bootstraps)\n",
    "    boot_c = np.zeros(n_bootstraps)\n",
    "    \n",
    "    for boot_idx in range(n_bootstraps):\n",
    "        boot_res_1a = np.random.choice(residuals_1a, size=len(residuals_1a), replace=True)\n",
    "        boot_res_1b = np.random.choice(residuals_1b, size=len(residuals_1b), replace=True)\n",
    "        boot_actual_1a = fitted_1a + boot_res_1a\n",
    "        boot_actual_1b = fitted_1b + boot_res_1b\n",
    "        \n",
    "        w, B0, h, b, c, _, _ = optimize_sample_with_geom(sample_idx, boot_actual_1a, boot_actual_1b, geom_param)\n",
    "        \n",
    "        boot_w[boot_idx] = w\n",
    "        boot_B0[boot_idx] = B0\n",
    "        boot_h[boot_idx] = h\n",
    "        boot_b[boot_idx] = b\n",
    "        boot_c[boot_idx] = c\n",
    "    \n",
    "    w_mean = np.mean(boot_w, axis=0)\n",
    "    w_std = np.std(boot_w, axis=0)\n",
    "    w_ci_low = np.percentile(boot_w, 2.5, axis=0)\n",
    "    w_ci_high = np.percentile(boot_w, 97.5, axis=0)\n",
    "    \n",
    "    B0_mean = np.mean(boot_B0)\n",
    "    B0_std = np.std(boot_B0)\n",
    "    B0_ci = np.percentile(boot_B0, [2.5, 97.5])\n",
    "    \n",
    "    h_mean = np.mean(boot_h)\n",
    "    h_std = np.std(boot_h)\n",
    "    h_ci = np.percentile(boot_h, [2.5, 97.5])\n",
    "    \n",
    "    b_mean = np.mean(boot_b)\n",
    "    b_std = np.std(boot_b)\n",
    "    b_ci = np.percentile(boot_b, [2.5, 97.5])\n",
    "    \n",
    "    c_mean = np.mean(boot_c)\n",
    "    c_std = np.std(boot_c)\n",
    "    c_ci = np.percentile(boot_c, [2.5, 97.5])\n",
    "    \n",
    "    # Save CSV\n",
    "    boot_data = {\n",
    "        'Wavelength_nm': selected_wavelengths,\n",
    "        'w_mean': w_mean,\n",
    "        'w_std': w_std,\n",
    "        'w_ci_low': w_ci_low,\n",
    "        'w_ci_high': w_ci_high\n",
    "    }\n",
    "    boot_df = pd.DataFrame(boot_data)\n",
    "    boot_file = os.path.join(output_root, f'bootstrap_w_uncertainty_New_Tree_ID_{new_id}.csv')\n",
    "    boot_df.to_csv(boot_file, index=False)\n",
    "    \n",
    "    # Plot w uncertainty\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(selected_wavelengths, w_mean, label='Mean w', color='blue')\n",
    "    plt.fill_between(selected_wavelengths, w_ci_low, w_ci_high, color='blue', alpha=0.3, label='95% CI')\n",
    "    plt.xlabel('Wavelength (nm)')\n",
    "    plt.ylabel('w')\n",
    "    plt.legend()\n",
    "    w_uncert_file = os.path.join(output_root, f'w_uncertainty_plot_New_Tree_ID_{new_id}.png')\n",
    "    plt.savefig(w_uncert_file, dpi=600, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return boot_w, boot_B0, boot_h, boot_b, boot_c\n",
    "\n",
    "# Parallel Bootstrap\n",
    "print(\"Starting parallel bootstrap uncertainty analysis...\")\n",
    "boot_results = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(bootstrap_sample)(i, actual_reflectance_1a[i], actual_reflectance_1b[i], fit_1a_list[i], fit_1b_list[i], all_geom[i], new_tree_id[i]) \n",
    "    for i in range(n_samples)\n",
    ")\n",
    "\n",
    "# ==============================================================\n",
    "# 13. Overall Bootstrap Uncertainty (No Title)\n",
    "# ==============================================================\n",
    "all_boot_w = np.vstack([res[0] for res in boot_results])\n",
    "\n",
    "overall_w_mean = np.mean(all_boot_w, axis=0)\n",
    "overall_w_std = np.std(all_boot_w, axis=0)\n",
    "overall_w_ci_low = np.percentile(all_boot_w, 2.5, axis=0)\n",
    "overall_w_ci_high = np.percentile(all_boot_w, 97.5, axis=0)\n",
    "\n",
    "overall_boot_df = pd.DataFrame({\n",
    "    'Wavelength_nm': selected_wavelengths,\n",
    "    'w_mean': overall_w_mean,\n",
    "    'w_std': overall_w_std,\n",
    "    'w_ci_low': overall_w_ci_low,\n",
    "    'w_ci_high': overall_w_ci_high\n",
    "})\n",
    "overall_boot_file = os.path.join(output_root, \"overall_bootstrap_w_uncertainty.csv\")\n",
    "overall_boot_df.to_csv(overall_boot_file, index=False)\n",
    "print(f\"Overall bootstrap w uncertainty saved → {overall_boot_file}\")\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(selected_wavelengths, overall_w_mean, label='Overall Mean w', color='green')\n",
    "plt.fill_between(selected_wavelengths, overall_w_ci_low, overall_w_ci_high, color='green', alpha=0.3, label='95% CI')\n",
    "plt.xlabel('Wavelength (nm)')\n",
    "plt.ylabel('w')\n",
    "plt.legend()\n",
    "overall_uncert_file = os.path.join(output_root, \"overall_w_uncertainty_plot.png\")\n",
    "plt.savefig(overall_uncert_file, dpi=600, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Overall w uncertainty plot saved → {overall_uncert_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
