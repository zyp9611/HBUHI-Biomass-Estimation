{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144 wavelength band columns\n",
      "Successfully read shice_merged.csv using encoding gbk\n",
      "Smoothing complete! Processed 75 samples, 144 bands\n",
      "Saved to: E:\\jupyter_data\\Hapke\\Submit\\data\\processed\\analyzes\\w.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "import os\n",
    "\n",
    "# Define file paths\n",
    "input_file = r\"E:\\jupyter_data\\Hapke\\Submit\\data\\processed\\Hapke_result\\hapke_parameters_merged.csv\"\n",
    "shice_file = r\"E:\\jupyter_data\\Hapke\\Submit\\data\\Original\\shice_merged.csv\"\n",
    "output_dir = r\"E:\\jupyter_data\\Hapke\\Submit\\data\\processed\\analyzes\"\n",
    "output_file = os.path.join(output_dir, \"w.csv\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load main data\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Identify wavelength band columns\n",
    "band_cols = [col for col in df.columns if col.startswith('w_') and col.endswith('nm')]\n",
    "print(f\"Found {len(band_cols)} wavelength band columns\")\n",
    "\n",
    "# Extract w matrix: rows=samples, columns=bands\n",
    "w_matrix = df[band_cols].values  # shape: (n_samples, n_bands)\n",
    "\n",
    "# Set SG parameters\n",
    "window_size = 5\n",
    "poly_order = 2\n",
    "\n",
    "# Ensure window does not exceed number of bands\n",
    "n_bands = w_matrix.shape[1]\n",
    "if window_size > n_bands:\n",
    "    window_size = n_bands if n_bands % 2 == 1 else n_bands - 1\n",
    "if window_size < 3:\n",
    "    raise ValueError(\"Too few bands to apply smoothing\")\n",
    "\n",
    "# Apply SG smoothing for each sample (row)\n",
    "smoothed_matrix = np.zeros_like(w_matrix)\n",
    "for i in range(w_matrix.shape[0]):\n",
    "    smoothed_matrix[i] = savgol_filter(w_matrix[i], window_size, poly_order)\n",
    "\n",
    "# Insert smoothed data back into DataFrame\n",
    "df_smoothed = df.copy()\n",
    "df_smoothed[band_cols] = smoothed_matrix\n",
    "\n",
    "# Read shice_merged.csv, compatible with multiple encodings\n",
    "shice_encoding_tried = False\n",
    "encodings_to_try = ['utf-8', 'gbk', 'gb2312', 'latin1']\n",
    "for enc in encodings_to_try:\n",
    "    try:\n",
    "        df_shice = pd.read_csv(shice_file, encoding=enc)\n",
    "        print(f\"Successfully read shice_merged.csv using encoding {enc}\")\n",
    "        shice_encoding_tried = True\n",
    "        break\n",
    "    except UnicodeDecodeError:\n",
    "        continue\n",
    "if not shice_encoding_tried:\n",
    "    raise RuntimeError(\"Unable to decode shice_merged.csv, please check the file encoding. Tried: \" + \", \".join(encodings_to_try))\n",
    "\n",
    "# Check for required columns in shice_merged\n",
    "needed_cols = {'Original_Tree_ID', 'New_Tree_ID', 'AGB'}\n",
    "missing_in_shice = needed_cols - set(df_shice.columns)\n",
    "if missing_in_shice:\n",
    "    raise KeyError(f\"shice_merged.csv is missing required fields: {missing_in_shice}\")\n",
    "\n",
    "# Use Original_Tree_ID to map New_Tree_ID and AGB from shice_merged\n",
    "# The New_Tree_ID in the result always comes from shice_merged.csv\n",
    "df_smoothed = df_smoothed.copy()\n",
    "df_smoothed['New_Tree_ID'] = np.nan\n",
    "df_smoothed['AGB'] = np.nan\n",
    "\n",
    "# Set Original_Tree_ID as the index in shice_merged for fast lookup\n",
    "shice_lookup = df_shice.set_index('Original_Tree_ID')\n",
    "\n",
    "# Use Series.map for order and NaN safety\n",
    "df_smoothed['New_Tree_ID'] = df_smoothed['Original_Tree_ID'].map(shice_lookup['New_Tree_ID'])\n",
    "df_smoothed['AGB'] = df_smoothed['Original_Tree_ID'].map(shice_lookup['AGB'])\n",
    "\n",
    "# Build final column order\n",
    "final_cols = ['New_Tree_ID', 'Original_Tree_ID', 'AGB'] + band_cols\n",
    "missing_in_df = [col for col in final_cols if col not in df_smoothed.columns]\n",
    "if missing_in_df:\n",
    "    print(f\"Warning: Some columns are missing: {missing_in_df}, filling with NaN\")\n",
    "    for col in missing_in_df:\n",
    "        df_smoothed[col] = np.nan\n",
    "\n",
    "# Reorder columns\n",
    "df_output = df_smoothed[[col for col in final_cols if col in df_smoothed.columns]]\n",
    "\n",
    "# Save output\n",
    "df_output.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Smoothing complete! Processed {w_matrix.shape[0]} samples, {n_bands} bands\")\n",
    "print(f\"Saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "# ==================== Configure Paths (Please make sure the paths are correct) ====================\n",
    "INPUT_FILE_PATH = r\"E:\\jupyter_data\\Hapke\\Submit\\data\\processed\\analyzes\\w.csv\"\n",
    "OUTPUT_DIR = r\"E:\\jupyter_data\\Hapke\\Submit\\data\\processed\\TBI\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "start_total_time = time.time()\n",
    "\n",
    "# ==================== 37 TBI Formulas ====================\n",
    "def tbi1(Ii, Ij, Ik): return (Ii - Ij) / (Ik + 1e-10)\n",
    "def tbi2(Ii, Ij, Ik): return Ik / (Ii - Ij + 1e-10)\n",
    "def tbi3(Ii, Ij, Ik): return Ii / (Ij + Ik + 1e-10)\n",
    "def tbi4(Ii, Ij, Ik): return (Ii + Ij) / (Ik + 1e-10)\n",
    "def tbi5(Ii, Ij, Ik): return (Ii + Ij) * Ik\n",
    "def tbi6(Ii, Ij, Ik): return (Ii - Ij) * Ik\n",
    "def tbi7(Ii, Ij, Ik): return Ii * Ij * Ik\n",
    "def tbi8(Ii, Ij, Ik): return Ii * Ij / (Ik + 1e-10)\n",
    "def tbi9(Ii, Ij, Ik): return Ii / ((Ij * Ik) + 1e-10)\n",
    "def tbi10(Ii, Ij, Ik): return Ii + Ij + Ik\n",
    "def tbi11(Ii, Ij, Ik): return Ii - Ij - Ik\n",
    "def tbi12(Ii, Ij, Ik): return Ii - 2 * Ij + Ik\n",
    "def tbi13(Ii, Ij, Ik): return (Ii - Ij) / (Ij - Ik + 1e-10)\n",
    "def tbi14(Ii, Ij, Ik): return (Ii + Ij) / (Ij + Ik + 1e-10)\n",
    "def tbi15(Ii, Ij, Ik): return (Ii - Ij) / (Ij + Ik + 1e-10)\n",
    "def tbi16(Ii, Ij, Ik): return (Ii + Ij) / (Ij - Ik + 1e-10)\n",
    "def tbi17(Ii, Ij, Ik): return Ii / (Ii + Ij + Ik + 1e-10)\n",
    "def tbi18(Ii, Ij, Ik): return (Ii - Ij) / (Ii + Ij + Ik + 1e-10)\n",
    "def tbi19(Ii, Ij, Ik): return (Ii + Ij) / (Ii + Ij + Ik + 1e-10)\n",
    "def tbi20(Ii, Ij, Ik): return (Ii - Ij - Ik) / (Ii + Ij + Ik + 1e-10)\n",
    "def tbi21(Ii, Ij, Ik): return (Ii - 2 * Ij + Ik) / (Ii + Ij + Ik + 1e-10)\n",
    "def tbi22(Ii, Ij, Ik): return Ii / (Ii - 2 * Ij + Ik + 1e-10)\n",
    "def tbi23(Ii, Ij, Ik): return Ij / (Ii - 2 * Ij + Ik + 1e-10)\n",
    "def tbi24(Ii, Ij, Ik): return (Ii - Ij) / (Ii - 2 * Ij + Ik + 1e-10)\n",
    "def tbi25(Ii, Ij, Ik): return (Ii - Ik) / (Ii - 2 * Ij + Ik + 1e-10)\n",
    "def tbi26(Ii, Ij, Ik): return (Ii + Ij) / (Ii - 2 * Ij + Ik + 1e-10)\n",
    "def tbi27(Ii, Ij, Ik): return (Ii + Ik) / (Ii - 2 * Ij + Ik + 1e-10)\n",
    "def tbi28(Ii, Ij, Ik): return (Ii - Ij - Ik) / (Ii - 2 * Ij + Ik + 1e-10)\n",
    "def tbi29(Ii, Ij, Ik): return (Ii + Ij + Ik) / (Ii - 2 * Ij + Ik + 1e-10)\n",
    "def tbi30(Ii, Ij, Ik): return Ii / (Ii - Ij - Ik + 1e-10)\n",
    "def tbi31(Ii, Ij, Ik): return Ij / (Ii - Ij - Ik + 1e-10)\n",
    "def tbi32(Ii, Ij, Ik): return (Ii - Ij) / (Ii - Ij - Ik + 1e-10)\n",
    "def tbi33(Ii, Ij, Ik): return (Ij - Ik) / (Ii - Ij - Ik + 1e-10)\n",
    "def tbi34(Ii, Ij, Ik): return (Ii + Ij) / (Ii - Ij - Ik + 1e-10)\n",
    "def tbi35(Ii, Ij, Ik): return (Ik + Ij) / (Ii - Ij - Ik + 1e-10)\n",
    "def tbi36(Ii, Ij, Ik): return (Ii + Ij + Ik) / (Ii - Ij - Ik + 1e-10)\n",
    "def tbi37(Ii, Ij, Ik): return (Ii - 2 * Ij + Ik) / (Ii - Ij - Ik + 1e-10)\n",
    "\n",
    "formulas = [tbi1, tbi2, tbi3, tbi4, tbi5, tbi6, tbi7, tbi8, tbi9, tbi10,\n",
    "            tbi11, tbi12, tbi13, tbi14, tbi15, tbi16, tbi17, tbi18, tbi19, tbi20,\n",
    "            tbi21, tbi22, tbi23, tbi24, tbi25, tbi26, tbi27, tbi28, tbi29, tbi30,\n",
    "            tbi31, tbi32, tbi33, tbi34, tbi35, tbi36, tbi37]\n",
    "formula_names = [f\"TBI{i}\" for i in range(1, 38)]\n",
    "\n",
    "# ==================== Parallel Calculation for TBI ====================\n",
    "def compute_tbi(args):\n",
    "    i, j, k, X, y, formulas, formula_names, y_mean = args\n",
    "    results = []\n",
    "    Ii, Ij, Ik = X[:, i], X[:, j], X[:, k]\n",
    "    \n",
    "    for idx, formula in enumerate(formulas):\n",
    "        try:\n",
    "            tbi = formula(Ii, Ij, Ik)\n",
    "            finite_mask = np.isfinite(tbi) & np.isfinite(y)\n",
    "            if np.sum(finite_mask) < max(10, len(y) // 3):\n",
    "                continue\n",
    "\n",
    "            tbi_valid = tbi[finite_mask]\n",
    "            y_valid = y[finite_mask]\n",
    "            if len(np.unique(tbi_valid)) <= 1:\n",
    "                continue\n",
    "\n",
    "            model = LinearRegression().fit(tbi_valid.reshape(-1, 1), y_valid)\n",
    "            y_pred = model.predict(tbi_valid.reshape(-1, 1))\n",
    "\n",
    "            r2 = r2_score(y_valid, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "            mae = mean_absolute_error(y_valid, y_pred)\n",
    "            rRMSE = rmse / y_mean if y_mean > 0 else np.inf\n",
    "            corr = np.corrcoef(tbi_valid, y_valid)[0, 1]\n",
    "\n",
    "            results.append((i, j, k, idx, r2, rmse, rRMSE, mae, formula_names[idx], corr))\n",
    "        except Exception:\n",
    "            continue\n",
    "    return results\n",
    "\n",
    "# ==================== Main Function ====================\n",
    "def process_single_file():\n",
    "    if not os.path.exists(INPUT_FILE_PATH):\n",
    "        print(f\"Error: File does not exist!\\n{INPUT_FILE_PATH}\")\n",
    "        return\n",
    "\n",
    "    file_start_time = time.time()\n",
    "    print(f\"\\nStart processing file: {INPUT_FILE_PATH}\")\n",
    "\n",
    "    try:\n",
    "        data = pd.read_csv(INPUT_FILE_PATH).astype(np.float32)\n",
    "        print(f\"Data shape: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read data: {e}\")\n",
    "        return\n",
    "\n",
    "    if 'AGB' not in data.columns:\n",
    "        print(\"Error: Missing column 'AGB'\")\n",
    "        return\n",
    "\n",
    "    y = data['AGB'].values\n",
    "    y_mean = np.mean(y)\n",
    "    print(f\"Mean AGB: {y_mean:.2f}\")\n",
    "\n",
    "    # Extract spectral bands\n",
    "    spectral_columns = []\n",
    "    wavelengths = []\n",
    "    for col in data.columns:\n",
    "        match = re.match(r'.*?(\\d+)nm$', col)\n",
    "        if match:\n",
    "            spectral_columns.append(col)\n",
    "            wavelengths.append(int(match.group(1)))\n",
    "    \n",
    "    if not wavelengths:\n",
    "        print(\"Error: No spectral bands detected\")\n",
    "        return\n",
    "\n",
    "    wavelengths = np.array(wavelengths)\n",
    "    print(f\"Detected {len(wavelengths)} bands, range: {wavelengths.min()} - {wavelengths.max()} nm\")\n",
    "    X = data[spectral_columns].values\n",
    "\n",
    "    # All permutations of three different bands (i != j != k, order matters)\n",
    "    band_indices = list(range(len(wavelengths)))\n",
    "    band_combos = list(itertools.permutations(band_indices, 3))\n",
    "    print(f\"Total combinations: {len(band_combos):,} (P(n,3) = n×(n-1)×(n-2))\")\n",
    "\n",
    "    # === Parallel Calculation ===\n",
    "    tasks = [(i, j, k, X, y, formulas, formula_names, y_mean) for i, j, k in band_combos]\n",
    "    results_parallel = Parallel(n_jobs=-1, backend='loky')(\n",
    "        delayed(compute_tbi)(task) for task in tqdm(tasks, desc=\"Calculating 37 types of TBI\")\n",
    "    )\n",
    "\n",
    "    # === Merge Results ===\n",
    "    all_data = []\n",
    "    best_r2 = -1\n",
    "    best_rmse = float('inf')\n",
    "    best_rrmse = float('inf')\n",
    "    best_mae = float('inf')\n",
    "    best_combo = None\n",
    "    best_tbi = None\n",
    "\n",
    "    for res in results_parallel:\n",
    "        for item in res:\n",
    "            i, j, k, fidx, r2, rmse, rrmse, mae, tbi_name, corr = item\n",
    "            wi, wj, wk = wavelengths[i], wavelengths[j], wavelengths[k]\n",
    "            entry = {\n",
    "                'Wavelength_i': wi, 'Wavelength_j': wj, 'Wavelength_k': wk,\n",
    "                'TBI_Type': tbi_name, 'R2': r2, 'RMSE': rmse, 'rRMSE': rrmse,\n",
    "                'MAE': mae, 'Correlation': corr\n",
    "            }\n",
    "            all_data.append(entry)\n",
    "\n",
    "            if r2 > best_r2 or (abs(r2 - best_r2) < 1e-6 and rrmse < best_rrmse):\n",
    "                best_r2, best_rmse, best_rrmse, best_mae = r2, rmse, rrmse, mae\n",
    "                best_combo = (wi, wj, wk)\n",
    "                best_tbi = tbi_name\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(INPUT_FILE_PATH))[0]\n",
    "\n",
    "    # === Only save Top100 summary file ===\n",
    "    all_df = pd.DataFrame(all_data)\n",
    "    if not all_df.empty:\n",
    "        top100 = all_df.sort_values(by=['R2', 'rRMSE', 'MAE'], ascending=[False, True, True]).head(100)\n",
    "        top100_file = os.path.join(OUTPUT_DIR, \"w_top100_R2.csv\")\n",
    "        top100.to_csv(top100_file, index=False)\n",
    "        print(\"Top100 has been saved as w_top100_R2.csv\")\n",
    "    else:\n",
    "        print(\"No valid results, Top100 was not generated\")\n",
    "\n",
    "    # === Output results ===\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"File analysis finished: {base_name}\")\n",
    "    if best_combo:\n",
    "        print(f\"Best R²   : {best_r2:.4f}\")\n",
    "        print(f\"Best RMSE : {best_rmse:.4f}\")\n",
    "        print(f\"Best rRMSE: {best_rrmse:.4f} ({best_rrmse*100:.2f}%)\")\n",
    "        print(f\"Best MAE  : {best_mae:.4f}\")\n",
    "        print(f\"Best TBI  : {best_tbi}\")\n",
    "        print(f\"Best bands: {best_combo}\")\n",
    "    else:\n",
    "        print(\"No valid model found\")\n",
    "    print(f\"Total valid combinations: {len(all_data)}\")\n",
    "    print(f\"Processing time  : {time.time() - file_start_time:.2f} seconds\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "# ==================== Run ====================\n",
    "if __name__ == \"__main__\":\n",
    "    process_single_file()\n",
    "    total_time = time.time() - start_total_time\n",
    "    print(f\"\\nTotal runtime: {total_time:.2f} seconds ({total_time/3600:.2f} hours)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
